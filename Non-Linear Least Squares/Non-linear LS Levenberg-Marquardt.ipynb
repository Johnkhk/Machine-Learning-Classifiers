{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 283,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from scipy.io import loadmat  \n",
    "from numpy import random\n",
    "lstsq = np.linalg.lstsq\n",
    "norm  = np.linalg.norm"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## i.) Generating Data, Levenberg-Marquardt Algorithm multiple runs implementation\n",
    "Experimenting with different initial values of lambda we scaled it by 10^-5 and chose a stopping criterion of the residual being close enough to 0. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 341,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "def initialize(X, N):                  \n",
    "    k=3                     \n",
    "    X = random.randn(N,k) \n",
    "    Y=[]\n",
    "    for i in range(500):\n",
    "        Y.append(X[i][0]*X[i][1]+X[i][2])\n",
    "    Y = np.array(Y)\n",
    "    w = random.randn(16,1) \n",
    "    wk = random.randn(16,1) \n",
    "    lamb = random.randint(1, 10)\n",
    "    lambdak = random.randint(1, 10)\n",
    "    return lamb, lambdak, w, wk#, nn\n",
    "#xbar, lamb, lambdak, w, wk = initialize(X)\n",
    "def neural_net(X, w):\n",
    "    #nn = w[0]*np.tanh(w[1]*X[0]+w[2]*X[1]+w[3]*X[2]+w[4]) + w[5]*np.tanh(w[6]*X[0]+w[7]*X[1]+w[8]*X[2]+w[9]) + w[10]*np.tanh(w[11]*X[0]+w[12]*X[1]+w[13]*X[2]+w[14])+w[15]\n",
    "    stacked_nn = []\n",
    "    r=[]\n",
    "    for i in range(500):\n",
    "        entry = w[0]*np.tanh(w[1]*X[i][0]+w[2]*X[i][1]+w[3]*X[i][2]+w[4]) + w[5]*np.tanh(w[6]*X[i][0]+w[7]*X[i][1]+w[8]*X[i][2]+w[9]) + w[10]*np.tanh(w[11]*X[i][0]+w[12]*X[i][1]+w[13]*X[i][2]+w[14])+w[15]\n",
    "        stacked_nn.append(entry) #array of 500 elements each is a np array of 3\n",
    "        r.append(entry - y[i])\n",
    "    r = np.vstack(r)\n",
    "    r = r.reshape(500,1)\n",
    "    stacked_nn = np.vstack(stacked_nn)\n",
    "    stacked_nn = stacked_nn.reshape(500,1) \n",
    "    return stacked_nn, r # 500x3\n",
    "\n",
    "def jacobian(X, w):\n",
    "    dw1f = []\n",
    "    dw2f = []\n",
    "    dw3f = []\n",
    "    dw4f = []\n",
    "    dw5f = []\n",
    "    dw6f = []\n",
    "    dw7f = []\n",
    "    dw8f = []\n",
    "    dw9f = []\n",
    "    dw10f = []\n",
    "    dw11f = []\n",
    "    dw12f = []\n",
    "    dw13f = []\n",
    "    dw14f = []\n",
    "    dw15f = []\n",
    "    dw16f = []\n",
    "    Dfw = []\n",
    "    for i in range(500):\n",
    "        dw1f.append(np.tanh(w[1]*X[i][0]+w[2]*X[i][1]+w[3]*X[i][2]+w[4])) \n",
    "        dw2f.append(w[0]*X[i][0]*deriv_tanh(w[1]*X[i][0]+w[2]*X[i][1]+w[3]*X[i][2]+w[4]))\n",
    "        dw3f.append(w[0]*X[i][1]*deriv_tanh(w[1]*X[i][0]+w[2]*X[i][1]+w[3]*X[i][2]+w[4]))\n",
    "        dw4f.append(w[0]*X[i][2]*deriv_tanh(w[1]*X[i][0]+w[2]*X[i][1]+w[3]*X[i][2]+w[4]))\n",
    "        dw5f.append(w[0]*deriv_tanh(w[1]*X[i][0]+w[2]*X[i][1]+w[3]*X[i][2]+w[4]))\n",
    "        dw6f.append(np.tanh(w[6]*X[i][0]+w[7]*X[i][1]+w[8]*X[i][2]+w[9]))\n",
    "        dw7f.append(w[5]*X[i][0]*deriv_tanh(w[6]*X[i][0]+w[7]*X[i][1]+w[8]*X[i][2]+w[9]))\n",
    "        dw8f.append(w[5]*X[i][1]*deriv_tanh(w[6]*X[i][0]+w[7]*X[i][1]+w[8]*X[i][2]+w[9]))\n",
    "        dw9f.append(w[5]*X[i][2]*deriv_tanh(w[6]*X[i][0]+w[7]*X[i][1]+w[8]*X[i][2]+w[9]))\n",
    "        dw10f.append(w[5]*deriv_tanh(w[6]*X[i][0]+w[7]*X[i][1]+w[8]*X[i][2]+w[9]))\n",
    "        dw11f.append(np.tanh(w[6]*X[i][0]+w[7]*X[i][1]+w[8]*X[i][2]+w[9]))\n",
    "        dw12f.append(w[10]*X[i][0]*deriv_tanh(w[11]*X[i][0]+w[12]*X[i][1]+w[13]*X[i][2]+w[14]))\n",
    "        dw13f.append(w[10]*X[i][1]*deriv_tanh(w[11]*X[i][0]+w[12]*X[i][1]+w[13]*X[i][2]+w[14]))\n",
    "        dw14f.append(w[10]*X[i][2]*deriv_tanh(w[11]*X[i][0]+w[12]*X[i][1]+w[13]*X[i][2]+w[14]))\n",
    "        dw15f.append(w[11]*deriv_tanh(w[11]*X[i][0]+w[12]*X[i][1]+w[13]*X[i][2]+w[14]))\n",
    "        dw16f.append(np.array([1]))\n",
    "    Dfw.append(np.array(dw1f))\n",
    "    Dfw.append(np.array(dw2f))\n",
    "    Dfw.append(np.array(dw3f))\n",
    "    Dfw.append(np.array(dw4f))\n",
    "    Dfw.append(np.array(dw5f))\n",
    "    Dfw.append(np.array(dw6f))\n",
    "    Dfw.append(np.array(dw7f))\n",
    "    Dfw.append(np.array(dw8f))\n",
    "    Dfw.append(np.array(dw9f))\n",
    "    Dfw.append(np.array(dw10f))\n",
    "    Dfw.append(np.array(dw11f))\n",
    "    Dfw.append(np.array(dw12f))\n",
    "    Dfw.append(np.array(dw13f))\n",
    "    Dfw.append(np.array(dw14f))\n",
    "    Dfw.append(np.array(dw15f))\n",
    "    Dfw.append(np.array(dw16f))\n",
    "    #At this point array of 16 elements, each element is a 500x1 np array\n",
    "    \n",
    "    #print(len(dw15f))\n",
    "    #print(len(dw16f))\n",
    "    Dfw = np.vstack(Dfw)\n",
    "    Dfw = Dfw.reshape(500,16)\n",
    "    return Dfw #jacobian: 500X16 \n",
    "\n",
    "def question3b(Dfw, fw):\n",
    "    gradR = 2*np.dot(np.transpose(Dfw),fw)\n",
    "    return gradR\n",
    "\n",
    "def MOLS(Dfw, X, w, wk, lamb, lambdak): #Solves for 1 iteration given intial lambda and w\n",
    "    A1 = jacobian(X, wk)\n",
    "    b1 = np.dot(jacobian(X, wk),w) - (neural_net(X, wk)[1])\n",
    "    A2 = np.identity(16)\n",
    "    b2 = np.zeros((16,1))\n",
    "    A3 = np.identity(16)\n",
    "    b3 = wk\n",
    "    \n",
    "    A = []\n",
    "    b = []\n",
    "    \n",
    "    A.append(A1*np.sqrt(lamb))\n",
    "    A.append(A2*np.sqrt(lambdak))\n",
    "    A.append(A3)\n",
    "    A = np.vstack(A)\n",
    "    b.append(b1)\n",
    "    b.append(np.sqrt(lamb)*b2)\n",
    "    b.append(np.sqrt(lambdak)*b3)\n",
    "    b = np.vstack(b) # A, b are stacked matrices\n",
    "    \n",
    "    weights = lstsq(A, b, rcond=None)[0]\n",
    "    return weights\n",
    "\n",
    "def iterate(X, w, wk, lamb, lambdak):\n",
    "    lamb, lambdak, w, wk = initialize(X, N)\n",
    "    Dfw = jacobian(X, wk)\n",
    "    nn, r = neural_net(X,w)\n",
    "    gradR = 2*np.dot(np.transpose(Dfw),r)\n",
    "    w = MOLS(Dfw, X, w, wk, lamb, lambdak)\n",
    "    iterations = 20\n",
    "    store_w=[]\n",
    "    iterationaxis=[]\n",
    "    raxis = []\n",
    "    for i in range(iterations):\n",
    "        oldr = r\n",
    "        Dfw = jacobian(X, w)\n",
    "        nn, r = neural_net(X,w)\n",
    "        \n",
    "        iterationaxis.append(i)\n",
    "        raxis.append(norm(r))\n",
    "        if(norm(r)**2 <0.0001 or norm(gradR) <0.0001):\n",
    "            break\n",
    "        elif(norm(r)**2 < norm(oldr)**2):\n",
    "            lambdak=0.8*lambdak\n",
    "            w = MOLS(Dfw, X, w, wk, lamb, lambdak)\n",
    "            store_w.append(w)\n",
    "        else:\n",
    "            lambdak = 2*lambdak\n",
    "            #store_w.append(w)\n",
    "    iterationaxis=np.array(iterationaxis)\n",
    "    raxis = np.array(raxis)    \n",
    "    return store_w, iterationaxis, raxis\n",
    "\n",
    "def main(N):\n",
    "    lamb, lambdak, w, wk = initialize(X, N)\n",
    "    result, x, y= iterate(X, w, wk, lamb, lambdak)\n",
    "    fig,ax = plt.subplots(1)\n",
    "    ax.plot(x,y)\n",
    "    return result\n",
    "        \n",
    "    \n",
    "def deriv_tanh(x):\n",
    "    return 1.0 - np.tanh(x)**2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Testing the code\n",
    "Implementing mulyiple runs instead of a warm start, ran main to test the code, We can see a list of generated weights with the length of the list being iterations in which the condition that the norm got smaller was satisfied. This is because the only runs that are stored are satisfy this condition. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 342,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2\n",
      "(16, 1)\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "a = main(500)\n",
    "#print(a)\n",
    "print(len(a))\n",
    "print(a[0].shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## plotting value of training loss versus iterations\n",
    "fig,ax = plt.subplots(1)\n",
    "ax.plot(iterationaxis,raxis)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## ii.) Testing model on another set of generated points\n",
    "Running main again reinitializes initial set of generated points"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "a = main(50)\n",
    "b = main(100)\n",
    "b = main(300)\n",
    "print(len(a))\n",
    "print(a[0].shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    " w = MOLS(Dfw, X, w, wk, 4, 9)\n",
    "\n",
    "print(A.shape)\n",
    "print(b.shape)\n",
    "print(w)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Training Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
